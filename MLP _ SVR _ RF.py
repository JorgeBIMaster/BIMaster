{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MLP | SVR | RF.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNh/tpl9nMUXnCf49TBOJvH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VjBZyssWFgpi"},"source":["Importing libraries"]},{"cell_type":"code","metadata":{"id":"tRUpbxdAGDet"},"source":["!pip install neupy\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, ConcatDataset\n","from torch.utils.data import SubsetRandomSampler #split the dataset\n","\n","from sklearn.preprocessing import MinMaxScaler    \n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, r2_score\n","import math\n","\n","from sklearn.model_selection import KFold\n","\n","torch.manual_seed(0)\n","np.random.seed(0)\n","\n","import random\n","random.seed(0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TfSADIs7F9kg"},"source":["Read Data"]},{"cell_type":"code","metadata":{"id":"DOHnq18oGdeR"},"source":["path = r\"C:\\Users\\Yoiz Nu√±ez\\.spyder-py3\\Code\\RegressionPytorch\\dados_indoor_puc.csv\"\n","df = pd.read_csv(path)\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HMIbF2uXGElJ"},"source":["Create Input and Output Data"]},{"cell_type":"code","metadata":{"id":"HI6Z-gkyG7SX"},"source":["X = df.iloc[:, 0:-1]\n","y = df.iloc[:, -1]\n","\n","#Train - Validation - Test\n","# Train - Test\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","#Normalize input\n","scaler = MinMaxScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","X_train, y_train = np.array(X_train), np.array(y_train)\n","X_test, y_test = np.array(X_test), np.array(y_test)\n","\n","#Normalize output\n","y_train = y_train.reshape(-1, 1)\n","y_train = scaler.fit_transform(y_train)\n","y_test = y_test.reshape(-1, 1)\n","y_test = scaler.transform(y_test)\n","\n","#Convert Output Variable to Float\n","y_train, y_test = y_train.astype(float), y_test.astype(float),"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3kjTcLW_GUA4"},"source":["Multi-layer Perceptron"]},{"cell_type":"code","metadata":{"id":"1h73Hp4nGTPI"},"source":["mlpregressor = MLPRegressor(hidden_layer_sizes=144, \n","                            activation='relu',\n","                            solver='lbfgs',\n","                            alpha=0.003,\n","                            learning_rate_init=0.01,\n","                            momentum=0.9,\n","                            random_state=1, \n","                            max_iter=1000,\n","                            early_stopping=True)\n","\n","mlpregressor.fit(X_train,np.ravel(y_train))\n","mlpregressor\n","\n","predict_train = mlpregressor.predict(X_train)\n","y_pred = mlpregressor.predict(X_test)\n","\n","y_pred = y_pred.reshape(-1,1)\n","\n","y_pred_desn = scaler.inverse_transform(y_pred)\n","y_target_desn = scaler.inverse_transform(y_test)\n","\n","MSE = np.square(np.subtract(y_target_desn,y_pred_desn)).mean()\n","RMSE_desn = math.sqrt(MSE)\n","\n","from sklearn.metrics import r2_score\n","R2_score = r2_score(y_target_desn, y_pred_desn)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O4co-GqsGbuA"},"source":["Support Vector Regression (SVR)"]},{"cell_type":"code","metadata":{"id":"hiU8nigsGn0p"},"source":["from sklearn.svm import SVR\n","\n","regressor = SVR(kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=399, epsilon=0.001, \n","                shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n","\n","regressor.fit(X_train,np.ravel(y_train))\n","\n","y_pred = regressor.predict(X_test)\n","y_pred = y_pred.reshape(-1,1)\n","\n","y_pred_desn = scaler.inverse_transform(y_pred)\n","y_target_desn = scaler.inverse_transform(y_test)\n","\n","MSE = np.square(np.subtract(y_target_desn,y_pred_desn)).mean()\n","RMSE_desn = math.sqrt(MSE)\n","\n","from sklearn.metrics import r2_score\n","R2_score = r2_score(y_target_desn, y_pred_desn)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w1QFb1HpG4cq"},"source":["Random Forest"]},{"cell_type":"code","metadata":{"id":"NhzbXN8nG2M3"},"source":["from sklearn.ensemble import RandomForestRegressor\n","\n","rfmodel = RandomForestRegressor(n_estimators=168)\n","\n","rfmodel.fit(X_train, np.ravel(y_train))\n","\n","y_pred = rfmodel.predict(X_test)\n","\n","y_pred = y_pred.reshape(-1,1)\n","\n","y_pred_desn = scaler.inverse_transform(y_pred)\n","y_target_desn = scaler.inverse_transform(y_test)\n","\n","MSE = np.square(np.subtract(y_target_desn,y_pred_desn)).mean()\n","RMSE_desn = math.sqrt(MSE)\n","\n","from sklearn.metrics import r2_score\n","R2_score = r2_score(y_target_desn, y_pred_desn)"],"execution_count":null,"outputs":[]}]}